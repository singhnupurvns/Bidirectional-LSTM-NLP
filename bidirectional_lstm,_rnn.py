# -*- coding: utf-8 -*-
"""Bidirectional LSTM, RNN

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eZsL5gw7gToH2zX3HgErGEc-YQT72lq9
"""

from google.colab import drive
drive.mount("/content/drive")

!ls /content/drive/My\ Drive

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

csv_path = "/content/drive/My Drive/train.csv"
 df = pd.read_csv(csv_path)

df.head(4)

df.isnull().sum()

df.shape

df = df.dropna()

df.isnull().sum()

df.head(4)

x = df.drop("label",axis=1)

y = df["label"]

y.value_counts()

import tensorflow as tf

print(tf.__version__)

from tensorflow.keras.layers import Embedding
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.text import one_hot
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dense
from tensorflow.keras .layers import Bidirectional

voc_size = 5000

messages = x.copy()

import nltk
import re
from nltk.corpus import stopwords

nltk.download("stopwords")

from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()
messages.reset_index(drop=True,inplace=True)
corpus = []
for i in range(0,len(messages)):
  review = re.sub("[^a-zA-Z]"," ",messages["title"][i])
  review = review.lower()
  review = review.split()
  review = [ps.stem(word)for word in review if not word in stopwords.words("english")]
  review = " ".join(review)
  corpus.append(review)

corpus

one_hot_repr = [one_hot(words,voc_size)for words in corpus]

one_hot_repr

corpus[1]

one_hot_repr[1]

sent_length = 20
embedded_docs = pad_sequences(one_hot_repr,padding= "pre",maxlen = sent_length)

embedded_docs

embedded_docs[1]

# Create the model
embedding_vector_features= 40
model = Sequential()
model.add(Embedding(input_dim=voc_size, output_dim=embedding_vector_features))
model.add(Bidirectional(LSTM(100)))
model.add(Dense(1, activation="sigmoid"))

# Compile the model
model.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])

# Build the model with input shape
model.build(input_shape=(None, sent_length))  # Explicitly setting input shape

# Print the model summary
print(model.summary())

len(embedded_docs),y.shape

import numpy as np
x_final = np.array(embedded_docs)
y_final = np.array(y)

x_final.shape,y_final.shape

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x_final,y_final,test_size=0.33,random_state=42)

model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=20,batch_size=32)

y_pred = model.predict(x_test)

y_pred

y_pred = np.where(y_pred > 0.5, 1.0, 0.0)

y_pred

from sklearn.metrics import confusion_matrix,accuracy_score ,classification_report
confusion_matrix(y_test,y_pred)

accuracy_score(y_test,y_pred)

print(classification_report(y_test,y_pred))

# Compute the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix
plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Pred 0", "Pred 1"], yticklabels=["Actual 0", "Actual 1"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

